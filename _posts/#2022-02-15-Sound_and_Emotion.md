---
layout: single
classes : wide
author_profile: true
title: Sound and Emotion
toc: true
toc_label : Table of contents
toc_icon: "list"
canonical_url: "https://srimouli04.github.io/sound_and_emotion"
excerpt: "The pros and cons of bias and variance trade off"
toc_sticky : false

header-includes: |
    \usepackage{tikz,pgfplots}
    \usepackage{fancyhdr}
    \pagestyle{fancy}
    \fancyhead[CO,CE]{This is fancy}
    \fancyfoot[CO,CE]{So is this}
    \fancyfoot[LE,RO]{\thepage}

---

Sounds have been a phenomenal source of communication since multicellular animal life has begun its communication on the planet. Humans have always leveraged sounds to communicate, whether information or emotions. Humans have endeavoured to master their creation by learning to speak, have a conversation, sing a song, or invent musical instruments, always striving for new tonalities and better systems.

Humans communicate through expressive gestures of emotions and sentiments identified through experience and knowledge. These emotions might be expressed verbally or via body language. Emotions are a natural aspect of human life and, among other things, have a significant influence on decision making. The varieties of traits that may contain additional details well about the emotional significance of each utterance are examined in this research. The characteristics that contribute to emotions may differ between spoken languages.

In recent years, computer-aided emotion recognition has been a subject of attention. An effective human emotion detection algorithm will aid in making human-computer interaction more natural and pleasant. It has numerous uses in education, entertainment, customer service, etc. As two significant indicators of an effective human state, speech and facial expression play essential roles in emotion recognition.  Individuals express their emotions in a variety of ways. Recognizing emotions is a challenging problem because human emotions lack temporal constraints and are diverse.


## Significance of Emotion Tagging 

Emotions play a critical role in daily human interactions. The sentiment present in the sentences’
utterances can change the entire meaning of the uttered sentence. For example, a sentence like
“I am hungry!” can be interpreted differently when the tone of utterance changes; the sentence
could be interpreted as the person feeling hungry when the utterance is usual. Still, the same
can mean the person is not hungry when the tone of the phrase is sarcastic. Often the change in
the meaning of the sentence can be observed with audio or visual cues. Furthermore, as humans
already have past experiences, the human brain can process this information naturally.
Nevertheless, when the same behaviour has to be mimicked on a computer, the task becomes
difficult because a computer cannot inherently distinguish emotions. Hence it becomes essential
to train the computer with suitable algorithms and tagged emotions to perform the task of
emotion classification.

The automatic recognition of spontaneous emotions from the speech is a challenging task. On
the one hand, acoustic features need to be robust enough to capture the emotional content for
various speaking styles. On the other, machine learning algorithms need to be insensitive to
outliers while modelling the context.

Several game-changing advances have been observed, since the advent of deep neural networks in
the last decade, in several established pattern recognition areas, such as an object, speech, and
speaker recognition, as well as in combined problem-solving approaches, such as audio-visual
recognition and the relatively new field of para linguistics. Emotion recognition can find
applications in different domains. For example, call centres can use emotion recognition in call
centres, where the goal is to detect the caller’s emotional state and provide feedback for the
quality of the service.

## Weakly Supervised Learning

“Weakly Supervised Learning” or “Weak supervision” is a branch of machine learning in which
noisy, restricted, or inaccurate sources are employed to give supervision signals for categorizing
vast volumes of training data in a supervised learning scenario. This methodology ameliorates
the burden of acquiring hand-labelled data sets, which can be expensive or onerous. Instead, low-cost weak labels are applied with the awareness that they are imprecise but can still be used
to build a powerful prediction model.

![Weakly Supervised Learning](\assets\images\weaksupervision.jpeg)

##References 